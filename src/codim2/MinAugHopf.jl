"""
For an initial guess from the index of a Hopf bifurcation point located in ContResult.specialpoint, returns a point which can be refined using `newton_hopf`.
"""
function hopf_point(br::AbstractBranchResult, index::Int)
    if br.specialpoint[index].type != :hopf 
        error("The provided index does not refer to a Hopf point")
    end
    specialpoint = br.specialpoint[index] # Hopf point
    p = specialpoint.param                # parameter value at the Hopf point
    Ï‰ = imag(br.eig[specialpoint.idx].eigenvals[specialpoint.ind_ev]) # frequency at the Hopf point
    return BorderedArray(specialpoint.x, [p, Ï‰] )
end
###################################################################################################
# this function encodes the functional
function (ğ‡::HopfProblemMinimallyAugmented)(x, p::ğ’¯, Ï‰::ğ’¯, params) where ğ’¯
    # These are the equations of the minimally augmented (MA) formulation of the 
    # Hopf bifurcation point
    # input:
    # - x guess for the point at which the jacobian has a purely imaginary eigenvalue
    # - p guess for the parameter for which the jacobian has a purely imaginary eigenvalue
    # The jacobian of the MA problem is solved with a BLS method
    # â”Œ         â”â”Œ  â”   â”Œ â”
    # â”‚ J-iÏ‰  a â”‚â”‚v â”‚ = â”‚0â”‚
    # â”‚  b    0 â”‚â”‚Ïƒ1â”‚   â”‚1â”‚
    # â””         â”˜â””  â”˜   â”” â”˜
    # In the notations of Govaerts 2000, a = w, b = v
    # Thus, b should be a null vector of J - iÏ‰
    #       a should be a null vector of J'+ iÏ‰
    a = ğ‡.a
    b = ğ‡.b
    # update parameter
    par = set(params, getlens(ğ‡), p)
    # we solve (J - iÏ‰)â‹…v + a Ïƒ1 = 0 with <b, v> = 1
    # note that the shift argument only affect J in this call:
    _, Ïƒ1, cv, = ğ‡.linbdsolver(jacobian(ğ‡.prob_vf, x, par), a, b, zero(ğ’¯), ğ‡.zero, one(ğ’¯); shift = Complex{ğ’¯}(0, -Ï‰))
    ~cv && @debug "[Hopf residual] Linear solver for (J-iÏ‰) did not converge."
    return residual(ğ‡.prob_vf, x, par), real(Ïƒ1), imag(Ïƒ1)
end

# this function encodes the functional
function (ğ‡::HopfProblemMinimallyAugmented)(x::BorderedArray, params)
    res = ğ‡(x.u, x.p[1], x.p[2], params)
    return BorderedArray(res[1], [res[2], res[3]])
end

@views function (ğ‡::HopfProblemMinimallyAugmented)(x::AbstractVector, params)
    res = ğ‡(x[begin:end-2], x[end-1], x[end], params)
    return vcat(res[1], res[2], res[3])
end
###################################################################################################
function _compute_bordered_vectors(ğ‡::HopfProblemMinimallyAugmented, J_at_xp, JAd_at_xp, Ï‰)
    a = ğ‡.a
    b = ğ‡.b
    ğ’¯ = eltype(ğ‡)

     # we solve (J-iÏ‰)v + a Ïƒ1 = 0 with <b, v> = 1
    v, _, cv, itv = ğ‡.linbdsolver(J_at_xp, a, b, zero(ğ’¯), ğ‡.zero, one(ğ’¯); shift = Complex{ğ’¯}(0, -Ï‰))
    ~cv && @debug "Bordered linear solver for (J-iÏ‰) did not converge."

    # we solve (J+iÏ‰)'w + b Ïƒ1 = 0 with <a, w> = 1
    w, _, cv, itw = ğ‡.linbdsolverAdjoint(JAd_at_xp, b, a, zero(ğ’¯), ğ‡.zero, one(ğ’¯); shift = Complex{ğ’¯}(0, Ï‰))
    ~cv && @debug "Bordered linear solver for (J+iÏ‰)' did not converge."

    return (; v, w, itv, itw)
end

function _get_bordered_terms(ğ‡::HopfProblemMinimallyAugmented, x, p::ğ’¯, Ï‰::ğ’¯, par) where ğ’¯
    # update parameter
    lens = getlens(ğ‡)
    par0 = set(par, lens, p)

    # This avoids doing 3 times the possibly costly building of J(x, p)
    J_at_xp = jacobian(ğ‡.prob_vf, x, par0)
    # Avoid computing J_at_xp twice in case ğ‡.Jadjoint is not provided
    JAd_at_xp = has_adjoint(ğ‡) ? jad(ğ‡.prob_vf, x, par0) : transpose(J_at_xp)

    (; v, w, itv, itw) = @time "--> bd_vec" _compute_bordered_vectors(ğ‡, J_at_xp, JAd_at_xp, Ï‰)

    Î´ = getdelta(ğ‡.prob_vf)
    Ïµ1, Ïµ2, Ïµ3 = ğ’¯(Î´), ğ’¯(Î´), ğ’¯(Î´)
    ################### computation of Ïƒx Ïƒp ####################
    # TODO!! This is only finite differences
    dâ‚šF   = (residual(ğ‡.prob_vf, x, set(par, lens, p + Ïµ1)) -
             residual(ğ‡.prob_vf, x, set(par, lens, p - Ïµ1))) / ğ’¯(2Ïµ1)
    dâ‚šJv = (apply(jacobian(ğ‡.prob_vf, x, set(par, lens, p + Ïµ3)), v) -
             apply(jacobian(ğ‡.prob_vf, x, set(par, lens, p - Ïµ3)), v)) / ğ’¯(2Ïµ3)
    Ïƒâ‚š = -dot(w, dâ‚šJv)

    # case of sigma_omega
    # ÏƒÏ‰ = dot(w, Complex{T}(0, 1) * v)
    ÏƒÏ‰ = Complex{ğ’¯}(0, 1) * dot(w, v)

    return (;J_at_xp, JAd_at_xp, dâ‚šF, Ïƒâ‚š, Î´, Ïµ2, v, w, par0, itv, itw, ÏƒÏ‰)
end
###################################################################################################
# since this is matrix based, it requires X to ba an AbstractVector
function jacobian(pdpb::HopfMAProblem{Tprob, MinAugMatrixBased}, X::AbstractVector{ğ’¯}, par) where {Tprob, ğ’¯}
    ğ‡ = pdpb.prob
    x = @view X[begin:end-2]
    p = X[end-1]
    Ï‰ = X[end]

    (;J_at_xp, JAd_at_xp, dâ‚šF, Ïƒâ‚š, Ïµ2, v, w, par0, ÏƒÏ‰) = _get_bordered_terms(ğ‡, x, p, Ï‰, par)

    cw = conj(w)
    vr = real(v); vi = imag(v)
    u1r = apply_jacobian(ğ‡.prob_vf, x + Ïµ2 * vr, par0, cw, true)
    u1i = apply_jacobian(ğ‡.prob_vf, x + Ïµ2 * vi, par0, cw, true)
    u2 = apply(JAd_at_xp,  cw)
    Ïƒxv2r = @. -(u1r - u2) / Ïµ2
    Ïƒxv2i = @. -(u1i - u2) / Ïµ2
    Ïƒâ‚“ = @. Ïƒxv2r + Complex{ğ’¯}(0, 1) * Ïƒxv2i

    Jhopf = hcat(_get_matrix(J_at_xp), dâ‚šF, zero(dâ‚šF))
    Jhopf = vcat(Jhopf, vcat(real(Ïƒâ‚“), real(Ïƒâ‚š), real(ÏƒÏ‰))')
    Jhopf = vcat(Jhopf, vcat(imag(Ïƒâ‚“), imag(Ïƒâ‚š), imag(ÏƒÏ‰))')
end
################################################################################
# Struct to invert the jacobian of the Hopf MA problem.
struct HopfLinearSolverMinAug <: AbstractLinearSolver; end

"""
This function solves the linear problem associated with a linearization of the minimally augmented formulation of the Hopf bifurcation point. The keyword `debugArray` is used to debug the routine by returning several key quantities.
"""
function _hopf_MA_linear_solver(x, p::ğ’¯, Ï‰::ğ’¯, ğ‡::HopfProblemMinimallyAugmented, par,
                            duu, dup, duÏ‰) where ğ’¯
    ################################################################################################
    # N = length(du) - 2
    # The Jacobian J of the vector field is expressed at (x, p)
    # the jacobian expression Jhopf of the hopf problem is
    #           â”Œ             â”
    #  Jhopf =  â”‚  J  dpF   0 â”‚
    #           â”‚ Ïƒx   Ïƒp  ÏƒÏ‰ â”‚
    #           â””             â”˜
    ########## Resolution of the bordered linear system ########
    # J * dX      + dpF * dp           = du => dX = x1 - dp * x2
    # The second equation
    #    <Ïƒx, dX> +  Ïƒp * dp + ÏƒÏ‰ * dÏ‰ = du[end-1:end]
    # thus becomes
    #   (Ïƒp - <Ïƒx, x2>) * dp + ÏƒÏ‰ * dÏ‰ = du[end-1:end] - <Ïƒx, x1>
    # This 2 x 2 system is then solved to get (dp, dÏ‰)
    ################### inversion of Jhopf ####################

    (;J_at_xp, JAd_at_xp, dâ‚šF, Ïƒâ‚š, Î´, Ïµ2, v, w, par0, itv, itw, ÏƒÏ‰) = _get_bordered_terms(ğ‡, x, p, Ï‰, par)

    # we solve Jâ‹…x1 = duu and Jâ‹…x2 = dâ‚šF
    x1, x2, cv, (it1, it2) = ğ‡.linsolver(J_at_xp, duu, dâ‚šF)
    ~cv && @debug "Linear solver for J did not converge"

    # the case of âˆ‚â‚“Ïƒ is a bit more involved
    # we first need to compute the value of âˆ‚â‚“Ïƒ written Ïƒx
    Ïƒx = similar(x, Complex{ğ’¯})

    if ğ‡.usehessian == false || has_hessian(ğ‡) == false
        cw = conj(w)
        vr = real(v); vi = imag(v)
        u1r = apply_jacobian(ğ‡.prob_vf, x + Ïµ2 * vr, par0, cw, true)
        u1i = apply_jacobian(ğ‡.prob_vf, x + Ïµ2 * vi, par0, cw, true)
        u2 = apply(JAd_at_xp,  cw)
        Ïƒxv2r = @. -(u1r - u2) / Ïµ2
        Ïƒxv2i = @. -(u1i - u2) / Ïµ2
        Ïƒx = @. Ïƒxv2r + Complex{ğ’¯}(0, 1) * Ïƒxv2i

        Ïƒxx1 = dot(Ïƒx, x1)
        Ïƒxx2 = dot(Ïƒx, x2)
    else
        d2Fv = d2F(ğ‡.prob_vf, x, par0, v, x1)
        Ïƒxx1 = -conj(dot(w, d2Fv))
        d2Fv = d2F(ğ‡.prob_vf, x, par0, v, x2)
        Ïƒxx2 = -conj(dot(w, d2Fv))
    end
    # We need to be careful here because the dot produces conjugates. 
    # Hence the + dot(Ïƒx, x2) and + imag(dot(Ïƒx, x1) and not the opposite
    LS = Matrix{ğ’¯}(undef, 2, 2);
    rhs = Vector{ğ’¯}(undef, 2);
    LS[1,1] = real(Ïƒâ‚š - Ïƒxx2); LS[1,2] = real(ÏƒÏ‰)
    LS[2,1] = imag(Ïƒâ‚š + Ïƒxx2); LS[2,2] = imag(ÏƒÏ‰)
    rhs[1] = dup - real(Ïƒxx1); rhs[2] =  duÏ‰ + imag(Ïƒxx1)
    dp, dÏ‰ = LS \ rhs
    return x1 .- dp .* x2, dp, dÏ‰, true, it1 + it2 + sum(itv) + sum(itw)
end

function (hopfl::HopfLinearSolverMinAug)(Jhopf, du::BorderedArray{vectype, ğ’¯}; kwargs...)  where {vectype, ğ’¯}
    # kwargs is used by AbstractLinearSolver
    out = _hopf_MA_linear_solver((Jhopf.x).u, #!! TODO !! This seems TU
                (Jhopf.x).p[1],
                (Jhopf.x).p[2],
                Jhopf.hopfpb,
                Jhopf.params,
                du.u, du.p[1], du.p[2])
    return BorderedArray{vectype, ğ’¯}(out[1], [out[2], out[3]]), out[4], out[5]
end
###################################################################################################
# define a problem <: AbstractBifurcationProblem
@inline has_adjoint(hopfpb::HopfMAProblem) = has_adjoint(hopfpb.prob)
@inline is_symmetric(hopfpb::HopfMAProblem) = is_symmetric(hopfpb.prob)
@inline getdelta(hopfpb::HopfMAProblem) = getdelta(hopfpb.prob)
residual(hopfpb::HopfMAProblem, x, p) = hopfpb.prob(x, p)
residual!(hopfpb::HopfMAProblem, out, x, p) = (copyto!(out, hopfpb.prob(x, p)); out)
save_solution(::HopfMAProblem, x ,p) = x

# jacobian(hopfpb::HopfMAProblem, x, p) = hopfpb.jacobian(x, p)
jacobian(hopfpb::HopfMAProblem{Tprob, Nothing}, x, p) where {Tprob} = (x = x, params = p, hopfpb = hopfpb.prob)

jacobian(hopfpb::HopfMAProblem{Tprob, AutoDiff}, x, p) where {Tprob} = ForwardDiff.jacobian(z -> hopfpb.prob(z, p), x)

jacobian(hopfpb::HopfMAProblem{Tprob, FiniteDifferences}, x, p) where {Tprob} = finite_differences( z -> hopfpb.prob(z, p), x; Î´ = 1e-8)

jacobian(hopfpb::HopfMAProblem{Tprob, FiniteDifferencesMF}, x, p) where {Tprob} = dx -> (hopfpb.prob(x .+ 1e-8 .* dx, p) .- hopfpb.prob(x .- 1e-8 .* dx, p)) / (2e-8)
###################################################################################################
"""
$(SIGNATURES)

This function turns an initial guess for a Hopf point into a solution to the Hopf problem based on a Minimally Augmented formulation. The arguments are as follows
- `prob::AbstractBifurcationProblem` where `p` is a set of parameters.
- `hopfpointguess` initial guess (x_0, p_0) for the Hopf point. It should a `BorderedArray` as returned by the function `HopfPoint`.
- `par` parameters used for the vector field
- `eigenvec` guess for the  iÏ‰ eigenvector
- `eigenvec_ad` guess for the -iÏ‰ eigenvector
- `options::NewtonPar` options for the Newton-Krylov algorithm, see [`NewtonPar`](@ref).

# Optional arguments:
- `normN = norm`
- `bdlinsolver` bordered linear solver for the constraint equation
- `kwargs` keywords arguments to be passed to the regular Newton-Krylov solver

# Simplified call:
Simplified call to refine an initial guess for a Hopf point. More precisely, the call is as follows

    newton_hopf(br::AbstractBranchResult, ind_hopf::Int; normN = norm, options = br.contparams.newton_options, kwargs...)

The parameters / options are as usual except that you have to pass the branch `br` from the result of a call to `continuation` with detection of bifurcations enabled and `index` is the index of bifurcation point in `br` you want to refine. You can pass newton parameters different from the ones stored in `br` by using the argument `options`.

!!! tip "Jacobian transpose"
    The adjoint of the jacobian `J` is computed internally when `Jáµ— = nothing` by using `transpose(J)` which works fine when `J` is an `AbstractArray`. In this case, do not pass the jacobian adjoint like `Jáµ— = (x, p) -> transpose(d_xF(x, p))` otherwise the jacobian will be computed twice!

!!! tip "ODE problems"
    For ODE problems, it is more efficient to use the Matrix based Bordered Linear Solver passing the option `bdlinsolver = MatrixBLS()`
"""
function newton_hopf(prob,
            hopfpointguess::BorderedArray,
            par,
            eigenvec, eigenvec_ad,
            options::NewtonPar;
            normN = norm,
            bdlinsolver::AbstractBorderedLinearSolver = MatrixBLS(),
            usehessian = true,
            kwargs...)
    # we first need to update d2F and d3F for them to accept complex arguments

    hopfproblem = HopfProblemMinimallyAugmented(
        prob,
        _copy(eigenvec_ad), # this is pb.a â‰ˆ null space of (J - iÏ‰ I)^*
        _copy(eigenvec),    # this is pb.b â‰ˆ null space of  J - iÏ‰ I
        options.linsolver,
        # do not change linear solver if user provides it
        @set bdlinsolver.solver = (isnothing(bdlinsolver.solver) ? options.linsolver : bdlinsolver.solver);
        usehessian = usehessian)

    prob_h = HopfMAProblem(hopfproblem, nothing, hopfpointguess, par, nothing, prob.plotSolution, prob.recordFromSolution)

    # options for the Newton Solver
    opt_hopf = @set options.linsolver = HopfLinearSolverMinAug()

    # solve the hopf equations
    return solve(prob_h, Newton(), opt_hopf; normN, kwargs...)
end

function newton_hopf(br::AbstractBranchResult, ind_hopf::Int;
            prob = br.prob,
            normN = norm,
            options = br.contparams.newton_options,
            verbose = true,
            nev = br.contparams.nev,
            start_with_eigen = false,
            kwargs...)
    hopfpointguess = hopf_point(br, ind_hopf)
    Ï‰ = hopfpointguess.p[2]
    bifpt = br.specialpoint[ind_hopf]
    options.verbose && println("--> Newton Hopf, the eigenvalue considered here is ", br.eig[bifpt.idx].eigenvals[bifpt.ind_ev])
    @assert bifpt.idx == bifpt.step + 1 "Error, the bifurcation index does not refer to the correct step."
    @assert ~isempty(br.eig[bifpt.idx].eigenvecs) "You must save the eigenvectors for this to work."
    Î¶ = geteigenvector(options.eigsolver, br.eig[bifpt.idx].eigenvecs, bifpt.ind_ev)
    Î¶ ./= normN(Î¶)
    Î¶ad = LinearAlgebra.conj.(Î¶)

    if start_with_eigen
        # computation of adjoint eigenvalue. Recall that b should be a null vector of J-iÏ‰
        Î» = Complex(0, Ï‰)
        p = bifpt.param
        parbif = setparam(br, p)

        # jacobian at bifurcation point
        L = jacobian(prob, bifpt.x, parbif)

        # computation of adjoint eigenvector
        _Jt = ~has_adjoint(prob) ? adjoint(L) : jad(prob, bifpt.x, parbif)

        Î¶star, Î»star = get_adjoint_basis(_Jt, conj(Î»), options.eigsolver; nev = nev, verbose = false)
        Î¶ad .= Î¶star ./ dot(Î¶star, Î¶)
    end

    # solve the hopf equations
    return newton_hopf(prob, hopfpointguess, getparams(br), Î¶, Î¶ad, options; normN, kwargs...)
end

"""
$(SIGNATURES)

codim 2 continuation of Hopf points. This function turns an initial guess for a Hopf point into a curve of Hopf points based on a Minimally Augmented formulation. The arguments are as follows
- `prob::AbstractBifurcationProblem`
- `hopfpointguess` initial guess (x_0, p1_0) for the Hopf point. It should be a `Vector` or a `BorderedArray`
- `par` set of parameters
- `lens1` parameter axis for parameter 1
- `lens2` parameter axis for parameter 2
- `eigenvec` guess for the iÏ‰ eigenvector at p1_0
- `eigenvec_ad` guess for the -iÏ‰ eigenvector at p1_0
- `options_cont` keywords arguments to be passed to the regular [`continuation`](@ref)

# Optional arguments:
- `jacobian_ma::Symbol = :autodiff`, how the linear system of the Fold problem is solved. Can be `:autodiff, :finiteDifferencesMF, :finiteDifferences, :minaug`
- `linsolve_adjoint` solver for (J+iÏ‰)^* â‹…sol = rhs
- `bdlinsolver` bordered linear solver for the constraint equation with top-left block (J-iÏ‰). Required in the linear solver for the Minimally Augmented Hopf functional. This option can be used to pass a dedicated linear solver for example with specific preconditioner.
- `bdlinsolver_adjoint` bordered linear solver for the constraint equation with top-left block (J-iÏ‰)^*. Required in the linear solver for the Minimally Augmented Hopf functional. This option can be used to pass a dedicated linear solver for example with specific preconditioner.
- `update_minaug_every_step` update vectors `a,b` in Minimally Formulation every `update_minaug_every_step` steps
- `compute_eigen_elements = false` whether to compute eigenelements. If `options_cont.detect_event>0`, it allows the detection of ZH, HH points.
- `kwargs` keywords arguments to be passed to the regular [`continuation`](@ref)

# Simplified call:

    continuation_hopf(br::AbstractBranchResult, ind_hopf::Int, lens2::AllOpticTypes, options_cont::ContinuationPar ;  kwargs...)

where the parameters are as above except that you have to pass the branch `br` from the result of a call to `continuation` with detection of bifurcations enabled and `index` is the index of Hopf point in `br` that you want to refine.

!!! tip "ODE problems"
    For ODE problems, it is more efficient to use the Matrix based Bordered Linear Solver passing the option `bdlinsolver = MatrixBLS()`. This is the default setting.

!!! tip "Jacobian transpose"
    The adjoint of the jacobian `J` is computed internally when `Jáµ— = nothing` by using `transpose(J)` which works fine when `J` is an `AbstractArray`. In this case, do not pass the jacobian adjoint like `Jáµ— = (x, p) -> transpose(d_xF(x, p))` otherwise the jacobian would be computed twice!

!!! tip "Detection of Bogdanov-Takens and Bautin bifurcations"
    In order to trigger the detection, pass `detect_event = 1,2` in `options_cont`. Note that you need to provide `d3F` in `prob`.
"""
function continuation_hopf(prob_vf, alg::AbstractContinuationAlgorithm,
                hopfpointguess::BorderedArray{vectype, Tb}, par,
                lens1::AllOpticTypes, lens2::AllOpticTypes,
                eigenvec, eigenvec_ad,
                options_cont::ContinuationPar ;
                update_minaug_every_step = 1,
                normC = norm,

                linsolve_adjoint = options_cont.newton_options.linsolver,
                bdlinsolver::AbstractBorderedLinearSolver = MatrixBLS(),
                bdlinsolver_adjoint::AbstractBorderedLinearSolver = bdlinsolver,

                jacobian_ma::AbstractJacobianType = AutoDiff(),
                compute_eigen_elements = false,
                usehessian = true,
                kind = HopfCont(),
                massmatrix = LinearAlgebra.I,
                record_from_solution = nothing,
                kwargs...) where {Tb, vectype}
    @assert lens1 != lens2 "Please choose 2 different parameters. You only passed $lens1"
    @assert lens1 == getlens(prob_vf)

    # options for the Newton Solver inherited from the ones the user provided
    options_newton = options_cont.newton_options
    # tolerance for detecting BT bifurcation and stopping continuation
    threshBT = 100options_newton.tol

    ğ‡ = HopfProblemMinimallyAugmented(
        prob_vf,
        _copy(eigenvec_ad), # this is a â‰ˆ null space of (J - iÏ‰ I)^*
        _copy(eigenvec),    # this is b â‰ˆ null space of  J - iÏ‰ I
        options_newton.linsolver,
        # do not change linear solver if user provides it
        @set bdlinsolver.solver = (isnothing(bdlinsolver.solver) ? options_newton.linsolver : bdlinsolver.solver);
        linsolve_adjoint = linsolve_adjoint,
        linbdsolve_adjoint = bdlinsolver_adjoint,
        usehessian,
        massmatrix,
        _norm = normC,
        update_minaug_every_step
        )

    # Jacobian for the Hopf problem
    if jacobian_ma == AutoDiff()
        hopfpointguess = vcat(hopfpointguess.u, hopfpointguess.p)
        prob_hopf = HopfMAProblem(ğ‡, AutoDiff(), hopfpointguess, par, lens2, prob_vf.plotSolution, prob_vf.recordFromSolution)
        opt_hopf_cont = @set options_cont.newton_options.linsolver = DefaultLS()
    elseif jacobian_ma == FiniteDifferencesMF()
        hopfpointguess = vcat(hopfpointguess.u, hopfpointguess.p)
        prob_hopf = HopfMAProblem(ğ‡, FiniteDifferencesMF(), hopfpointguess, par, lens2, prob_vf.plotSolution, prob_vf.recordFromSolution)
        opt_hopf_cont = @set options_cont.newton_options.linsolver = options_cont.newton_options.linsolver
    elseif jacobian_ma == FiniteDifferences()
        hopfpointguess = vcat(hopfpointguess.u, hopfpointguess.p)
        prob_hopf = HopfMAProblem(ğ‡, FiniteDifferences(), hopfpointguess, par, lens2, prob_vf.plotSolution, prob_vf.recordFromSolution)
        opt_hopf_cont = @set options_cont.newton_options.linsolver = options_cont.newton_options.linsolver
    elseif jacobian_ma == MinAugMatrixBased()
        hopfpointguess = vcat(hopfpointguess.u, hopfpointguess.p)
        prob_hopf = HopfMAProblem(ğ‡, MinAugMatrixBased(), hopfpointguess, par, lens2, prob_vf.plotSolution, prob_vf.recordFromSolution)
        opt_hopf_cont = @set options_cont.newton_options.linsolver = options_cont.newton_options.linsolver
    else
        prob_hopf = HopfMAProblem(ğ‡, nothing, hopfpointguess, par, lens2, prob_vf.plotSolution, prob_vf.recordFromSolution)
        opt_hopf_cont = @set options_cont.newton_options.linsolver = HopfLinearSolverMinAug()
    end

    # this functions allows to tackle the case where the two parameters have the same name
    lenses = get_lens_symbol(lens1, lens2)

    # current lyapunov coefficient
    eTb = eltype(Tb)
    ğ‡.l1 = Complex{eTb}(0, 0)
    ğ‡.BT = one(eTb)
    ğ‡.GH = one(eTb)

    # this function is used as a Finalizer
    # it is called to update the Minimally Augmented problem
    # by updating the vectors a, b
    function update_minaug_hopf(z, tau, step, contResult; kUP...)
        # user-passed finalizer
        finaliseUser = get(kwargs, :finalise_solution, nothing)

        # we first check that the continuation step was successful
        # if not, we do not update the problem with bad information!
        # if we are in a bisection, we still update the MA problem, this does not work well otherwise
        success = get(kUP, :state, nothing).converged
        if (~mod_counter(step, update_minaug_every_step) || success == false)
            # we call the user finalizer
            return isnothing(finaliseUser) ? true : finaliseUser(z, tau, step, contResult; prob = ğ‡, kUP...)
        end

        @debug "[Hopf] Update vectors a and b"
        x = getvec(z.u, ğ‡)   # hopf point
        p1, Ï‰ = getp(z.u, ğ‡) # first parameter
        p2 = z.p              # second parameter
        newpar = set(par, lens1, p1)
        newpar = set(newpar, lens2, p2)

        # expression of the jacobian
        J_at_xp = jacobian(ğ‡.prob_vf, x, newpar)
        JAd_at_xp = has_adjoint(ğ‡) ? jad(ğ‡.prob_vf, x, newpar) : adjoint(J_at_xp)

        bd_vec = _compute_bordered_vectors(ğ‡, J_at_xp, JAd_at_xp, Ï‰)

        ğ‡.a .= bd_vec.w ./ normC(bd_vec.w)
        # do not normalize with dot(newb, ğ‡.a), it prevents from BT detection
        ğ‡.b .= bd_vec.v ./ normC(bd_vec.v)

        # we stop continuation at Bogdanov-Takens points
        # CA NE DEVRAIT PAS ETRE ISSNOT?
        isbt = isnothing(contResult) ? true : isnothing(findfirst(x -> x.type in (:bt, :ghbt, :btgh), contResult.specialpoint))

        # if the frequency is null, this is not a Hopf point, we halt the process
        if abs(Ï‰) < threshBT
            @warn "[Codim 2 Hopf - Finalizer] The Hopf curve seems to be close to a BT point: Ï‰ â‰ˆ $Ï‰. Stopping computations at ($p1, $p2). If the BT point is not detected, try lowering Newton tolerance or dsmax."
        end

        # call the user-passed finalizer
        final_result = isnothing(finaliseUser) ? true : finaliseUser(z, tau, step, contResult; prob = ğ‡, kUP...)

        return abs(Ï‰) >= threshBT && isbt && final_result
    end

    # the following allows to append information specific to the codim 2 continuation to the user data
    _printsol = record_from_solution
    _printsol2 = isnothing(_printsol) ?
        (u, p; kw...)  -> begin
                 (; zip(lenses, (getp(u, ğ‡)[1], p))..., 
                            Ï‰â‚• = getp(u, ğ‡)[2],
                            l1 = ğ‡.l1,
                            BT = ğ‡.BT,
                            GH = ğ‡.GH,
                            _namedrecordfromsol(BifurcationKit.record_from_solution(prob_vf)(getvec(u, ğ‡), p; kw...))...
                            )
            end :
        (u, p; kw...) -> begin
            (; zip(lenses, (getp(u, ğ‡)[1], p))..., 
                        Ï‰â‚• = getp(u, ğ‡)[2],
                        l1 = ğ‡.l1,
                        BT = ğ‡.BT,
                        GH = ğ‡.GH,
                        _namedrecordfromsol(_printsol(getvec(u, ğ‡), p; kw...))...
                        )
        end

    prob_hopf = re_make(prob_hopf, record_from_solution = _printsol2)

    # eigen solver
    eigsolver = HopfEig(getsolver(opt_hopf_cont.newton_options.eigsolver), prob_hopf)

    # Define event for detecting codim 2 bifurcations.
    # Couple it with user passed events
    event_user = get(kwargs, :event, nothing)
    event_bif = ContinuousEvent(2, test_bt_gh, compute_eigen_elements, ("bt", "gh"), threshBT)

    if compute_eigen_elements #|| event_user == BifDetectEvent
        if isnothing(event_user)
            event = PairOfEvents(event_bif, BifDetectEvent)
        else
            event = SetOfEvents(event_bif, BifDetectEvent, event_user)
        end
        # careful here, we need to adjust the tolerance for stability to avoid
        # spurious ZH or HH bifurcations
        @reset opt_hopf_cont.tol_stability = max(10opt_hopf_cont.newton_options.tol, opt_hopf_cont.tol_stability)
    else
        if isnothing(event_user)
            event = event_bif
        else
            event = PairOfEvents(event_bif, event_user)
        end
    end

    prob_hopf = re_make(prob_hopf, record_from_solution = _printsol2)

    # solve the hopf equations
    br = continuation(
                prob_hopf, alg,
                (@set opt_hopf_cont.newton_options.eigsolver = eigsolver);
                kwargs...,
                kind = kind,
                linear_algo = BorderingBLS(solver = opt_hopf_cont.newton_options.linsolver, check_precision = false),
                normC = normC,
                finalise_solution = update_minaug_every_step == 0 ? get(kwargs, :finalise_solution, finalise_default) : update_minaug_hopf,
                event = event
            )
    @assert ~isnothing(br) "Empty branch!"
    return correct_bifurcation(br)
end

function continuation_hopf(prob,
                        br::AbstractBranchResult, ind_hopf::Int64,
                        lens2::AllOpticTypes,
                        options_cont::ContinuationPar = br.contparams;
                        alg = br.alg,
                        normC = norm,
                        nev = br.contparams.nev,
                        start_with_eigen = false,
                        bdlinsolver::AbstractBorderedLinearSolver = MatrixBLS(),
                        bdlinsolver_adjoint = bdlinsolver,
                        a = nothing,
                        b = nothing,
                        kwargs...)
    hopfpointguess = hopf_point(br, ind_hopf)
    Ï‰ = hopfpointguess.p[2]
    bifpt = br.specialpoint[ind_hopf]

    if isnothing(br.eig) 
        error("The branch contains no eigen elements. This is strange because a Hopf point was detected. Please open an issue on the website.")
    end

    p = bifpt.param
    parbif = setparam(br, p)

    if start_with_eigen
        if ~haseigenvector(br)
            error("The branch contains no eigenvectors for the Hopf point.\nPlease provide one.")
        end
        Î¶ = geteigenvector(br.contparams.newton_options.eigsolver, br.eig[bifpt.idx].eigenvecs, bifpt.ind_ev)
        rmul!(Î¶, 1 / normC(Î¶))
        Î¶ad = conj.(Î¶)

        # computation of adjoint eigenvalue
        Î» = br.eig[bifpt.idx].eigenvals[bifpt.ind_ev]
        # jacobian at bifurcation point
        L = jacobian(prob, bifpt.x, parbif)

        # jacobian adjoint at bifurcation point
        Lâ˜… = ~has_adjoint(prob) ? adjoint(L) : jad(prob, bifpt.x, parbif)

        Î¶â˜…, Î»â˜… = get_adjoint_basis(Lâ˜…, conj(Î»), br.contparams.newton_options.eigsolver; nev = nev, verbose = options_cont.newton_options.verbose)
        axpby!(1 / dot(Î¶â˜…, Î¶), Î¶â˜…, 0, Î¶ad)
    else
        # we use a minimally augmented formulation to set the initial vectors
        # we start with a vector similar to an eigenvector
        Î¶ = _copy(getu0(br.prob))
        a = isnothing(a) ? _randn(Î¶) : a
        b = isnothing(b) ? _randn(Î¶) : b

        ğ’¯ = typeof(Ï‰)
        L = jacobian(prob, bifpt.x, parbif)
        newb, _, cv, it = bdlinsolver(L, a, b, zero(ğ’¯), zero(a), one(ğ’¯); shift = Complex{ğ’¯}(0, -Ï‰))
        ~cv && @debug "Bordered linear solver for (J-iÏ‰) did not converge."

        @debug "EIGENVECTORS" Ï‰ cv it norminf(residual(prob, bifpt.x, parbif)) norminf(apply(L,newb) - complex(0,Ï‰)*newb) norminf(apply(L,newb) + complex(0,Ï‰)*newb)

        Lâ˜… = ~has_adjoint(prob) ? adjoint(L) : jad(prob, bifpt.x, parbif)
        newa, _, cv, it = bdlinsolver_adjoint(Lâ˜…, b, a, zero(ğ’¯), zero(a), one(ğ’¯); shift = Complex{ğ’¯}(0, Ï‰))
        ~cv && @debug "Bordered linear solver for (J+iÏ‰)' did not converge."

        @debug "EIGENVECTORS" Ï‰ cv it norminf(residual(prob, bifpt.x, parbif)) norminf(apply(Lâ˜…,newa) - complex(0,Ï‰)*newa) norminf(apply(Lâ˜…,newa) + complex(0,Ï‰)*newa)

        Î¶ad = newa ./ normC(newa)
        Î¶   = newb ./ normC(newb)
    end

    return continuation_hopf(br.prob, alg,
                    hopfpointguess, parbif,
                    getlens(br), lens2,
                    Î¶, Î¶ad,
                    options_cont ;
                    normC,
                    bdlinsolver,
                    bdlinsolver_adjoint,
                    kwargs...)
end

function test_bt_gh(iter, state)
    probma = getprob(iter)
    ğ‡ = probma.prob
    ğ’¯ = eltype(ğ‡) 
    lens1, lens2 = get_lenses(probma)

    z = getx(state)
    x = getvec(z, ğ‡)   # hopf point
    p1, Ï‰ = getp(z, ğ‡) # first parameter
    p2 = getp(state)   # second parameter
    par = getparams(probma)
    newpar = set(par, lens1, p1)
    newpar = set(newpar, lens2, p2)

    probhopf = iter.prob.prob

    a = probhopf.a
    b = probhopf.b

    # expression of the jacobian
    J_at_xp = jacobian(probhopf.prob_vf, x, newpar)
    JAd_at_xp = has_adjoint(probhopf) ? jad(probhopf.prob_vf, x, newpar) : transpose(J_at_xp)

    bd_vec = _compute_bordered_vectors(ğ‡, J_at_xp, JAd_at_xp, Ï‰)

    # compute new b
    Î¶ = bd_vec.v
    Î¶ ./= ğ‡.norm(Î¶)

    # compute new a
    Î¶â˜… = bd_vec.w

    # test function for Bogdanov-Takens
    probhopf.BT = Ï‰
    BT2 = real( dot(Î¶â˜… ./ ğ‡.norm(Î¶â˜…), Î¶) )
    Î¶â˜… ./= dot(Î¶, Î¶â˜…)
    @debug "Hopf normal form computation"
    hp0 = Hopf(x, nothing, p1, Ï‰, newpar, lens1, Î¶, Î¶â˜…, (a = zero(Complex{ğ’¯}), b = zero(Complex{ğ’¯})), :hopf)
    hp = hopf_normal_form(ğ‡.prob_vf, hp0, ğ‡.linsolver; verbose = false, autodiff = false) # TODO! WE NEED A KWARGS here
    # lyapunov coefficient
    probhopf.l1 = hp.nf.b
    # test for Bautin bifurcation.
    # If GH is too large, we take the previous value to avoid spurious detection
    # GH will be large close to BR points
    probhopf.GH = abs(real(hp.nf.b)) < 1e5 ? real(hp.nf.b) : state.eventValue[2][2]
    return probhopf.BT, probhopf.GH
end

# structure to compute the eigenvalues along the Hopf branch
struct HopfEig{P, S} <: AbstractCodim2EigenSolver
    eigsolver::S
    prob::P
end

function (eig::HopfEig)(Jma, nev; k...)
    n = min(nev, length(Jma.x.u))
    x = Jma.x.u     # hopf point
    p1, Ï‰ = Jma.x.p # first parameter
    newpar = set(Jma.params, getlens(Jma.hopfpb), p1)
    J = jacobian(Jma.hopfpb.prob_vf, x, newpar)
    eigenelts = eig.eigsolver(J, n; k...)
    return eigenelts
end

@views function (eig::HopfEig)(Jma::AbstractMatrix, nev; k...)
    eigenelts = eig.eigsolver(Jma[1:end-2, 1:end-2], nev; k...)
end

geteigenvector(eig::HopfEig, vectors, i::Int) = geteigenvector(eig.eigsolver, vectors, i)
